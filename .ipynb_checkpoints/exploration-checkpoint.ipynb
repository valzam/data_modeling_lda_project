{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/debate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trump = df[df[\"Speaker\"] == \"Trump\"][\"Text\"]\n",
    "clinton = df[df[\"Speaker\"] == \"Clinton\"][\"Text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341.78591549295777\n",
      "2703\n"
     ]
    }
   ],
   "source": [
    "print(trump.str.len().mean())\n",
    "print(trump.str.len().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440.2551440329218\n",
      "2376\n"
     ]
    }
   ],
   "source": [
    "print(clinton.str.len().mean())\n",
    "print(clinton.str.len().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic gensim topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a 2d array with the words in each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents_clean = trump.str.replace(\"\\.|\\?|-|!|'|,\", \"\")\n",
    "documents_clean = documents_clean[documents_clean.str.len() > 50]\n",
    "stoplist = list(gensim.parsing.preprocessing.STOPWORDS) + \\\n",
    "            [\"hes\", \"think\", \"weve\", \"thats\", \"said\", \"want\", \"look\", \"youve\", \"youre\"]\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove words that only appear once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "frequency =  defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1] for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a dictionary (word to id mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1059 unique tokens: ['thank', 'lester', 'jobs', 'country', 'theyre']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.filter_n_most_frequent(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the bag of words corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = gensim.models.LdaModel(corpus, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_words = [[word for word, _ in lda.show_topic(topicno, topn=50)] for topicno in range(lda.num_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doesnt millions donors took time let taxes companies percent hundreds\n",
      "russia good deal happened world energy china jobs talks hundreds\n",
      "war nato endorsed believe sean secretary hannity laws russia ill\n",
      "tremendous bad companies bring chicago jobs mosul need use world\n",
      "states disaster jobs happened lot believe happen whats didnt emails\n",
      "obamacare wants tax russia big bad percent regulations president new\n",
      "need cities law inner ive women care mosul got happen\n",
      "nafta wall bad trade signed heard border deal percent better\n",
      "isis good ive secretary world let talk politicians problem fed\n",
      "didnt bad talk time experience got iran companies effective campaign\n"
     ]
    }
   ],
   "source": [
    "for topics in top_words:\n",
    "    print(\" \".join(topics[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.014288354240350678), (1, 0.014289257614619936), (2, 0.014287534104115342), (3, 0.014286256067873048), (4, 0.014286761888813731), (5, 0.014290424627816264), (6, 0.8714051778973243), (7, 0.014287957221450008), (8, 0.01429167503625736), (9, 0.014286601301379379)]\n",
      "debate\n",
      "saying\n",
      "things\n",
      "let\n",
      "absolutely\n",
      "case\n"
     ]
    }
   ],
   "source": [
    "doc = 20\n",
    "print(lda.get_document_topics(corpus[doc]))\n",
    "[print(dictionary[id]) for id, _ in corpus[doc]];"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
