{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Papers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>403.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5834.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116.480327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5633.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5733.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5834.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5934.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6035.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id\n",
       "count   403.000000\n",
       "mean   5834.000000\n",
       "std     116.480327\n",
       "min    5633.000000\n",
       "25%    5733.500000\n",
       "50%    5834.000000\n",
       "75%    5934.500000\n",
       "max    6035.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>EventType</th>\n",
       "      <th>PdfName</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>PaperText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5677</td>\n",
       "      <td>Double or Nothing: Multiplicative Incentive Me...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>5677-double-or-nothing-multiplicative-incentiv...</td>\n",
       "      <td>Crowdsourcing has gained immense popularity in...</td>\n",
       "      <td>Double or Nothing: Multiplicative\\nIncentive M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5941</td>\n",
       "      <td>Learning with Symmetric Label Noise: The Impor...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>5941-learning-with-symmetric-label-noise-the-i...</td>\n",
       "      <td>Convex potential minimisation is the de facto ...</td>\n",
       "      <td>Learning with Symmetric Label Noise: The\\nImpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6019</td>\n",
       "      <td>Algorithmic Stability and Uniform Generalization</td>\n",
       "      <td>Poster</td>\n",
       "      <td>6019-algorithmic-stability-and-uniform-general...</td>\n",
       "      <td>One of the central questions in statistical le...</td>\n",
       "      <td>Algorithmic Stability and Uniform Generalizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6035</td>\n",
       "      <td>Adaptive Low-Complexity Sequential Inference f...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>6035-adaptive-low-complexity-sequential-infere...</td>\n",
       "      <td>We develop a sequential low-complexity inferen...</td>\n",
       "      <td>Adaptive Low-Complexity Sequential Inference f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5978</td>\n",
       "      <td>Covariance-Controlled Adaptive Langevin Thermo...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>5978-covariance-controlled-adaptive-langevin-t...</td>\n",
       "      <td>Monte Carlo sampling for Bayesian posterior in...</td>\n",
       "      <td>Covariance-Controlled Adaptive Langevin\\nTherm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id                                              Title  EventType  \\\n",
       "0  5677  Double or Nothing: Multiplicative Incentive Me...     Poster   \n",
       "1  5941  Learning with Symmetric Label Noise: The Impor...  Spotlight   \n",
       "2  6019   Algorithmic Stability and Uniform Generalization     Poster   \n",
       "3  6035  Adaptive Low-Complexity Sequential Inference f...     Poster   \n",
       "4  5978  Covariance-Controlled Adaptive Langevin Thermo...     Poster   \n",
       "\n",
       "                                             PdfName  \\\n",
       "0  5677-double-or-nothing-multiplicative-incentiv...   \n",
       "1  5941-learning-with-symmetric-label-noise-the-i...   \n",
       "2  6019-algorithmic-stability-and-uniform-general...   \n",
       "3  6035-adaptive-low-complexity-sequential-infere...   \n",
       "4  5978-covariance-controlled-adaptive-langevin-t...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Crowdsourcing has gained immense popularity in...   \n",
       "1  Convex potential minimisation is the de facto ...   \n",
       "2  One of the central questions in statistical le...   \n",
       "3  We develop a sequential low-complexity inferen...   \n",
       "4  Monte Carlo sampling for Bayesian posterior in...   \n",
       "\n",
       "                                           PaperText  \n",
       "0  Double or Nothing: Multiplicative\\nIncentive M...  \n",
       "1  Learning with Symmetric Label Noise: The\\nImpo...  \n",
       "2  Algorithmic Stability and Uniform Generalizati...  \n",
       "3  Adaptive Low-Complexity Sequential Inference f...  \n",
       "4  Covariance-Controlled Adaptive Langevin\\nTherm...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      403.000000\n",
       "mean     33776.503722\n",
       "std       3266.834148\n",
       "min      23590.000000\n",
       "25%      31469.000000\n",
       "50%      33990.000000\n",
       "75%      36009.500000\n",
       "max      42533.000000\n",
       "Name: PaperText, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"PaperText\"].str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic gensim topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a 2d array with the words in each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents_clean = df[\"Abstract\"].str.replace(\"\\.|\\?|-|!|'|,|:|\\+|-|=|(|)\", \"\")\n",
    "stoplist = list(gensim.parsing.preprocessing.STOPWORDS) + \\\n",
    "            [\"hes\", \"think\", \"weve\", \"thats\", \"said\", \"want\", \"look\", \n",
    "             \"youve\", \"youre\", \"model\", \"models\", \"method\", \"matrix\"] + \\\n",
    "            list(range(0,9))\n",
    "porter_stemmer = PorterStemmer()\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist and len(word) > 2] for document in documents_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove words that only appear once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "frequency =  defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1] for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a dictionary (word to id mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(3104 unique tokens: ['crowdsourcing', 'gained', 'popularity', 'machine', 'learning']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.filter_n_most_frequent(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the bag of words corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = gensim.models.LdaModel(corpus, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_words = [[word for word, _ in lda.show_topic(topicno, topn=50)] for topicno in range(lda.num_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: gradient approximation bounds regret known\n",
      "1: information space visual previous computational\n",
      "2: output bounds search functions gradient\n",
      "3: graph bounds tensor causal bound\n",
      "4: estimators statistical high deep network\n",
      "5: sparse bounds deep estimation convex\n",
      "6: network guarantees case convolutional constraints\n",
      "7: input network decision approaches classification\n",
      "8: setting space feature bounds functions\n",
      "9: image prediction questions network random\n"
     ]
    }
   ],
   "source": [
    "for topics,i in zip(top_words, range(0,len(top_words))):\n",
    "    print(str(i) + \": \" + \" \".join(topics[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0.9844801406773237)]\n",
      "Double or Nothing: Multiplicative Incentive Mechanisms for Crowdsourcing\n",
      "----------------------------------------\n",
      "[(9, 0.98420808514939861)]\n",
      "Learning with Symmetric Label Noise: The Importance of Being Unhinged\n",
      "----------------------------------------\n",
      "[(8, 0.98860588683921413)]\n",
      "Algorithmic Stability and Uniform Generalization\n",
      "----------------------------------------\n",
      "[(3, 0.98333043007784415)]\n",
      "Adaptive Low-Complexity Sequential Inference for Dirichlet Process Mixture Models\n",
      "----------------------------------------\n",
      "[(7, 0.98363189291490438)]\n",
      "Covariance-Controlled Adaptive Langevin Thermostat for Large-Scale Bayesian Sampling\n",
      "----------------------------------------\n",
      "[(4, 0.98448015154219104)]\n",
      "Robust Portfolio Optimization\n",
      "----------------------------------------\n",
      "[(7, 0.98732203089806936)]\n",
      "Logarithmic Time Online Multiclass prediction\n",
      "----------------------------------------\n",
      "[(0, 0.9678500381385039)]\n",
      "Planar Ultrametrics for Image Segmentation\n",
      "----------------------------------------\n",
      "[(2, 0.2249355230057227), (9, 0.76346750862091772)]\n",
      "Expressing an Image Stream with a Sequence of Natural Sentences\n",
      "----------------------------------------\n",
      "[(7, 0.98732143057223509)]\n",
      "Parallel Correlation Clustering on Big Graphs\n",
      "----------------------------------------\n",
      "[(1, 0.40175571747178362), (6, 0.40097385100412491), (8, 0.18793527320667811)]\n",
      "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\n",
      "----------------------------------------\n",
      "[(0, 0.96665862440868089)]\n",
      "Space-Time Local Embeddings\n",
      "----------------------------------------\n",
      "[(0, 0.96999267896169128)]\n",
      "A Convergent Gradient Descent Algorithm for Rank Minimization and Semidefinite Programming from Random Linear Measurements\n",
      "----------------------------------------\n",
      "[(1, 0.81585809337119086), (7, 0.1684520984381627)]\n",
      "Smooth Interactive Submodular Set Cover\n",
      "----------------------------------------\n",
      "[(1, 0.99010785147182201)]\n",
      "Galileo: Perceiving Physical Object Properties by Integrating a Physics Engine with Deep Learning\n",
      "----------------------------------------\n",
      "[(0, 0.98124807127980984)]\n",
      "On the Pseudo-Dimension of Nearly Optimal Auctions\n",
      "----------------------------------------\n",
      "[(0, 0.29877765486480157), (3, 0.68612337105767252)]\n",
      "Unlocking neural population non-stationarities using hierarchical dynamics models\n",
      "----------------------------------------\n",
      "[(8, 0.98333105312222346)]\n",
      "Bayesian Manifold Learning: The Locally Linear Latent Variable Model (LL-LVM)\n",
      "----------------------------------------\n",
      "[(3, 0.99117488612045912)]\n",
      "Color Constancy by Learning to Predict Chromaticity from Luminance\n",
      "----------------------------------------\n",
      "[(5, 0.78876268752984902), (8, 0.19305156509920338)]\n",
      "Fast and Accurate Inference of Plackett–Luce Models\n",
      "----------------------------------------\n",
      "[(2, 0.88495593078742385), (8, 0.09965632127021723)]\n",
      "Probabilistic Line Searches for Stochastic Optimization\n",
      "----------------------------------------\n",
      "[(4, 0.28140132033621457), (8, 0.052479255889763064), (9, 0.6486150872887525)]\n",
      "Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets\n",
      "----------------------------------------\n",
      "[(6, 0.98845914152130088)]\n",
      "Where are they looking?\n",
      "----------------------------------------\n",
      "[(0, 0.095142438156845324), (6, 0.88434146908170141)]\n",
      "The Pareto Regret Frontier for Bandits\n",
      "----------------------------------------\n",
      "[(3, 0.98714120981325559)]\n",
      "On the Limitation of Spectral Methods: From the Gaussian Hidden Clique Problem to Rank-One Perturbations of Gaussian Tensors\n",
      "----------------------------------------\n",
      "[(4, 0.98695365555546799)]\n",
      "Measuring Sample Quality with Stein's Method\n",
      "----------------------------------------\n",
      "[(6, 0.9898858923576509)]\n",
      "Bidirectional Recurrent Convolutional Networks for Multi-Frame Super-Resolution\n",
      "----------------------------------------\n",
      "[(0, 0.98474211220228236)]\n",
      "Bounding errors of Expectation-Propagation\n",
      "----------------------------------------\n",
      "[(7, 0.98874824694596364)]\n",
      "A fast, universal algorithm to learn parametric nonlinear embeddings\n",
      "----------------------------------------\n",
      "[(8, 0.98199643211420595)]\n",
      "Texture Synthesis Using Convolutional Neural Networks\n",
      "----------------------------------------\n",
      "[(0, 0.382653904054785), (3, 0.60574937828860675)]\n",
      "Extending Gossip Algorithms to Distributed Estimation of U-statistics\n",
      "----------------------------------------\n",
      "[(1, 0.083558216242233238), (3, 0.902644962534915)]\n",
      "Streaming, Distributed Variational Inference for Bayesian Nonparametrics\n",
      "----------------------------------------\n",
      "[(8, 0.98163022149286749)]\n",
      "Learning visual biases from human imagination\n",
      "----------------------------------------\n",
      "[(7, 0.98363227373015316)]\n",
      "Smooth and Strong: MAP Inference with Linear Convergence\n",
      "----------------------------------------\n",
      "[(0, 0.98499789110767699)]\n",
      "Copeland Dueling Bandits\n",
      "----------------------------------------\n",
      "[(3, 0.97567179529135228)]\n",
      "Optimal Ridge Detection using Coverage Risk\n",
      "----------------------------------------\n",
      "[(5, 0.97856618539733076)]\n",
      "Top-k Multiclass SVM\n",
      "----------------------------------------\n",
      "[(8, 0.96537936210950759)]\n",
      "Policy Evaluation Using the Ω-Return\n",
      "----------------------------------------\n",
      "[(0, 0.98695417501171856)]\n",
      "Orthogonal NMF through Subspace Exploration\n",
      "----------------------------------------\n",
      "[(3, 0.982349860491467)]\n",
      "Stochastic Online Greedy Learning with Semi-bandit Feedbacks\n",
      "----------------------------------------\n",
      "[(4, 0.49598111847600151), (9, 0.4927486559979195)]\n",
      "Deeply Learning the Messages in Message Passing Inference\n",
      "----------------------------------------\n",
      "[(4, 0.064460866174920542), (7, 0.92044228402150896)]\n",
      "Synaptic Sampling: A Bayesian Approach to Neural Network Plasticity and Rewiring\n",
      "----------------------------------------\n",
      "[(5, 0.98593568888214966)]\n",
      "Accelerated Proximal Gradient Methods for Nonconvex Programming\n",
      "----------------------------------------\n",
      "[(5, 0.97804567205032533)]\n",
      "Approximating Sparse PCA from Incomplete Data\n",
      "----------------------------------------\n",
      "[(4, 0.96537904842841882)]\n",
      "Nonparametric von Mises Estimators for Entropies, Divergences and Mutual Informations\n",
      "----------------------------------------\n",
      "[(3, 0.97428172538082913)]\n",
      "Column Selection via Adaptive Sampling\n",
      "----------------------------------------\n",
      "[(0, 0.026184125734033524), (5, 0.49223037940437242), (8, 0.47199408510199975)]\n",
      "HONOR: Hybrid Optimization for NOn-convex Regularized problems\n",
      "----------------------------------------\n",
      "[(1, 0.98043181617365294)]\n",
      "3D Object Proposals for Accurate Object Class Detection\n",
      "----------------------------------------\n",
      "[(0, 0.98830927958537784)]\n",
      "Algorithms with Logarithmic or Sublinear Regret for  Constrained Contextual Bandits\n",
      "----------------------------------------\n",
      "[(5, 0.9812474518088482)]\n",
      "Tensorizing Neural Networks\n",
      "----------------------------------------\n",
      "[(6, 0.98448021373312189)]\n",
      "Parallelizing MCMC with Random Partition Trees\n",
      "----------------------------------------\n",
      "[(0, 0.40543007577598877), (8, 0.57856643009260511)]\n",
      "A Reduced-Dimension fMRI Shared Response Model\n",
      "----------------------------------------\n",
      "[(7, 0.71137137216514856), (8, 0.27703181773839525)]\n",
      "Spectral Learning of Large Structured HMMs for Comparative Epigenomics\n",
      "----------------------------------------\n",
      "[(9, 0.97428223690614812)]\n",
      "Individual Planning in Infinite-Horizon Multiagent Settings: Inference, Structure and Scalability\n",
      "----------------------------------------\n",
      "[(0, 0.11336815630257165), (2, 0.27205266327567634), (6, 0.25797088027856546), (8, 0.16433908390055957), (9, 0.18638539667069376)]\n",
      "Estimating Mixture Models via Mixtures of Polynomials\n",
      "----------------------------------------\n",
      "[(0, 0.98548112543601252)]\n",
      "On the Global Linear Convergence of Frank-Wolfe Optimization Variants\n",
      "----------------------------------------\n",
      "[(6, 0.43637376861721894), (8, 0.54729592271700389)]\n",
      "Deep Knowledge Tracing\n",
      "----------------------------------------\n",
      "[(3, 0.9804322254767327)]\n",
      "Rethinking LDA: Moment Matching for Discrete ICA\n",
      "----------------------------------------\n",
      "[(3, 0.068254887771697234), (5, 0.92314057813888872)]\n",
      "Efficient Compressive Phase Retrieval with Constrained Sensing Vectors\n",
      "----------------------------------------\n",
      "[(0, 0.98235039998413154)]\n",
      "Barrier Frank-Wolfe for Marginal Inference\n",
      "----------------------------------------\n",
      "[(3, 0.96538032912724836)]\n",
      "Learning Theory and Algorithms for Forecasting Non-stationary Time Series\n",
      "----------------------------------------\n",
      "[(0, 0.081779835638132695), (5, 0.56549312275452979), (6, 0.18747518695425963), (7, 0.012259504987853578), (8, 0.14788916121178181)]\n",
      "Compressive spectral embedding: sidestepping the SVD\n",
      "----------------------------------------\n",
      "[(0, 0.10670316435177854), (4, 0.45735471579043685), (5, 0.42297618957819133)]\n",
      "A Nonconvex Optimization Framework for Low Rank Matrix Estimation\n",
      "----------------------------------------\n",
      "[(1, 0.042240288573245362), (9, 0.94266190063066291)]\n",
      "Automatic Variational Inference in Stan\n",
      "----------------------------------------\n",
      "[(5, 0.98615122174818937)]\n",
      "Attention-Based Models for Speech Recognition\n",
      "----------------------------------------\n",
      "[(4, 0.98499808149752854)]\n",
      "Closed-form Estimators for High-dimensional Generalized Linear Models\n",
      "----------------------------------------\n",
      "[(2, 0.97856710711696682)]\n",
      "Online F-Measure Optimization\n",
      "----------------------------------------\n",
      "[(9, 0.98124554344190473)]\n",
      "Online Rank Elicitation for Plackett-Luce: A Dueling Bandits Approach\n",
      "----------------------------------------\n",
      "[(1, 0.98474315271283919)]\n",
      "M-Best-Diverse Labelings for Submodular Energies and Beyond\n",
      "----------------------------------------\n",
      "[(4, 0.98234914579666499)]\n",
      "Tractable Bayesian Network Structure Learning with Bounded Vertex Cover Number\n",
      "----------------------------------------\n",
      "[(6, 0.9839257924919963)]\n",
      "Learning Large-Scale Poisson DAG Models based on OverDispersion Scoring\n",
      "----------------------------------------\n",
      "[(1, 0.98234961674857135)]\n",
      "Training Restricted Boltzmann Machine via the ￼Thouless-Anderson-Palmer free energy\n",
      "----------------------------------------\n",
      "[(6, 0.96249268874948768)]\n",
      "Character-level Convolutional Networks for Text Classification\n",
      "----------------------------------------\n",
      "[(7, 0.30284794122800157), (8, 0.68805957380667004)]\n",
      "Robust Feature-Sample Linear Discriminant Analysis for Brain Disorders Diagnosis\n",
      "----------------------------------------\n",
      "[(6, 0.98301643054955878)]\n",
      "Black-box optimization of noisy functions with unknown smoothness\n",
      "----------------------------------------\n",
      "[(8, 0.9844799414106904)]\n",
      "Recovering Communities in the General Stochastic Block Model Without Knowing the Parameters\n",
      "----------------------------------------\n",
      "[(7, 0.77124588672666927), (8, 0.21922785066766115)]\n",
      "Deep learning with Elastic Averaging SGD\n",
      "----------------------------------------\n",
      "[(0, 0.97999765842450459)]\n",
      "Monotone k-Submodular Function Maximization with Size Constraints\n",
      "----------------------------------------\n",
      "[(8, 0.98845949844157821)]\n",
      "Active Learning from Weak and Strong Labelers\n",
      "----------------------------------------\n",
      "[(8, 0.98420802040045519)]\n",
      "On the Optimality of Classifier Chain for Multi-label Classification\n",
      "----------------------------------------\n",
      "[(0, 0.8152950523692033), (5, 0.12873261933170818), (6, 0.044046646594299632)]\n",
      "Robust Regression via Hard Thresholding\n",
      "----------------------------------------\n",
      "[(7, 0.99174183161027485)]\n",
      "Sparse Local Embeddings for Extreme Multi-label Classification\n",
      "----------------------------------------\n",
      "[(0, 0.12368294679925611), (2, 0.41883275713335649), (8, 0.44789265756822294)]\n",
      "Solving Random Quadratic Systems of Equations Is Nearly as Easy as Solving Linear Systems\n",
      "----------------------------------------\n",
      "[(7, 0.98615113622515782)]\n",
      "A Framework for Individualizing Predictions of Disease Trajectories by Exploiting Multi-Resolution Structure\n",
      "----------------------------------------\n",
      "[(3, 0.97856765557817449)]\n",
      "Subspace Clustering with Irrelevant Features via Robust Dantzig Selector\n",
      "----------------------------------------\n",
      "[(7, 0.98732185099433745)]\n",
      "Sparse PCA via Bipartite Matchings\n",
      "----------------------------------------\n",
      "[(4, 0.059180218881218494), (5, 0.93014984297869263)]\n",
      "Fast Randomized Kernel Ridge Regression with Statistical Guarantees\n",
      "----------------------------------------\n",
      "[(9, 0.98268932707542056)]\n",
      "Online Learning for Adversaries with Memory: Price of Past Mistakes\n",
      "----------------------------------------\n",
      "[(4, 0.12020183420214091), (5, 0.86883663451425863)]\n",
      "Convolutional spike-triggered covariance analysis for neural subunit models\n",
      "----------------------------------------\n",
      "[(4, 0.98301544510951155)]\n",
      "Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\n",
      "----------------------------------------\n",
      "[(5, 0.98676161416465835)]\n",
      "GAP Safe screening rules for sparse multi-task and multi-class models\n",
      "----------------------------------------\n",
      "[(4, 0.79062660007633712), (8, 0.18583875751517606)]\n",
      "Empirical Localization of Homogeneous Divergences on Discrete Sample Spaces\n",
      "----------------------------------------\n",
      "[(4, 0.60845084599635535), (7, 0.3767315578444107)]\n",
      "Statistical Model Criticism using Kernel Two Sample Tests\n",
      "----------------------------------------\n",
      "[(4, 0.68868272718051338), (5, 0.30280518690932823)]\n",
      "Precision-Recall-Gain Curves: PR Analysis Done Right\n",
      "----------------------------------------\n",
      "[(0, 0.37867298577546199), (2, 0.35497419283328335), (6, 0.12438134030197234), (7, 0.13105985653515573)]\n",
      "A Generalization of Submodular Cover via the Diminishing Return Property on the Integer Lattice\n",
      "----------------------------------------\n",
      "[(2, 0.74001147736646378), (4, 0.24985993034074352)]\n",
      "Bidirectional Recurrent Neural Networks as Generative Models\n",
      "----------------------------------------\n",
      "[(0, 0.40946350831257761), (8, 0.57763049361880336)]\n",
      "Quartz: Randomized Dual Coordinate Ascent with Arbitrary Sampling\n",
      "----------------------------------------\n",
      "[(0, 0.31304768352506634), (7, 0.67731145492875944)]\n",
      "Maximum Likelihood Learning With Arbitrary Treewidth via Fast-Mixing Parameter Sets\n",
      "----------------------------------------\n",
      "[(5, 0.61211085153438138), (7, 0.37049473485775558)]\n",
      "Hessian-free Optimization for Learning Deep Multidimensional Recurrent Neural Networks\n",
      "----------------------------------------\n",
      "[(0, 0.97631331653332842)]\n",
      "Large-scale probabilistic predictors with and without guarantees of validity\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    "    doc = i\n",
    "    print(lda.get_document_topics(corpus[doc]))\n",
    "    print(df.loc[doc][\"Title\"])\n",
    "    print(\"----------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
